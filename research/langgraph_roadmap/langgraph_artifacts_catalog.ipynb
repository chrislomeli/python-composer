{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LangGraph Artifacts Catalog\n",
    "\n",
    "This notebook catalogs all proposed **nodes** and **tools** for the OSC LangGraph architecture.\n",
    "\n",
    "Each artifact follows the same pattern as `velocity_humanizer.ipynb`:\n",
    "1. **Purpose** - What it does\n",
    "2. **Input/Output Contract** - Data shapes\n",
    "3. **Tool Function Signature** - Pure function interface\n",
    "4. **LangGraph Node Wrapper** - Async state handler\n",
    "5. **OpenAI Function Schema** - For LLM tool calling (optional)\n",
    "6. **Example Usage**\n",
    "\n",
    "---\n",
    "\n",
    "## Artifact Categories\n",
    "\n",
    "| Category | Artifacts |\n",
    "|----------|----------|\n",
    "| **Generation** | `generate_clip_from_nl`, `generate_composition_from_nl` |\n",
    "| **Validation** | `validate_sml_clip`, `validate_sml_composition` |\n",
    "| **Expression** | `humanize_velocities`, `apply_cc_template`, `apply_pitch_bend` |\n",
    "| **Transformation** | `transpose_clip`, `quantize_clip`, `apply_swing`, `invert_clip`, `retrograde_clip` |\n",
    "| **Harmony** | `generate_chord_track`, `generate_bassline`, `arpeggiate_chords` |\n",
    "| **Playback** | `preview_clip`, `preview_composition` |\n",
    "| **Storage** | `store_clip`, `search_clips`, `load_dsl_project` |\n",
    "| **Export** | `export_clip_to_midi`, `export_composition_to_midi` |\n",
    "| **QA** | `lint_clip`, `summarize_clip` |"
   ],
   "id": "catalog-intro"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 1. GENERATION TOOLS\n",
    "---"
   ],
   "id": "generation-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.1 generate_clip_from_nl\n",
    "\n",
    "**Purpose**: Convert natural language prompt to SML clip using LangGraph + OpenAI.\n",
    "\n",
    "**Wraps**: `OSCFacade.natural_language_clip_to_sml` / `clip_graph.generate_sml_clip`\n",
    "\n",
    "**Input**: Natural language prompt string\n",
    "\n",
    "**Output**: SML clip dict with bars/items structure"
   ],
   "id": "generate-clip-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Any, Dict, Optional, TypedDict\n",
    "\n",
    "class GenerateClipParams(TypedDict, total=False):\n",
    "    prompt: str                      # Natural language description\n",
    "    num_bars: int                    # Target number of bars (default: 2)\n",
    "    key: str                         # Key signature (e.g., \"C\", \"F#\")\n",
    "    mode: str                        # \"major\" or \"minor\"\n",
    "    meter: str                       # Time signature (e.g., \"4/4\", \"3/4\")\n",
    "    style: str                       # Style hint (e.g., \"jazz\", \"classical\", \"lofi\")\n",
    "    instrument: str                  # Target instrument (e.g., \"piano\", \"bass\", \"strings\")\n",
    "    tempo_bpm: int                   # Reference tempo for duration choices\n",
    "\n",
    "\n",
    "def generate_clip_from_nl(\n",
    "    params: GenerateClipParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generate an SML clip from natural language.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: GenerateClipParams with at minimum a `prompt`\n",
    "    - Output: SML clip dict with structure:\n",
    "        {\n",
    "            \"name\": str,\n",
    "            \"bars\": [\n",
    "                {\n",
    "                    \"bar_index\": int,\n",
    "                    \"items\": [{\"note\": \"C4\", \"duration\": \"quarter\"}, ...]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    - Raises: ValueError if generation fails\n",
    "    \n",
    "    This wraps the existing clip_graph.generate_sml_clip flow.\n",
    "    \"\"\"\n",
    "    # Implementation wraps OSCFacade.natural_language_clip_to_sml\n",
    "    pass"
   ],
   "id": "generate-clip-signature"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LangGraph Node Wrapper\n",
    "\n",
    "class ClipGenerationState(TypedDict, total=False):\n",
    "    prompt: str\n",
    "    generate_params: GenerateClipParams\n",
    "    sml_clip: Dict[str, Any]\n",
    "    error: str\n",
    "\n",
    "\n",
    "async def generate_clip_node(state: ClipGenerationState) -> ClipGenerationState:\n",
    "    \"\"\"LangGraph node: Generate SML clip from prompt.\"\"\"\n",
    "    if state.get(\"error\"):\n",
    "        return state\n",
    "    \n",
    "    prompt = state.get(\"prompt\")\n",
    "    if not prompt:\n",
    "        return {**state, \"error\": \"No prompt provided\"}\n",
    "    \n",
    "    params = state.get(\"generate_params\", {})\n",
    "    params[\"prompt\"] = prompt\n",
    "    \n",
    "    try:\n",
    "        sml_clip = generate_clip_from_nl(params)\n",
    "        return {**state, \"sml_clip\": sml_clip}\n",
    "    except Exception as e:\n",
    "        return {**state, \"error\": f\"Generation failed: {e}\"}"
   ],
   "id": "generate-clip-node"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 2. VALIDATION TOOLS\n",
    "---"
   ],
   "id": "validation-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 validate_sml_clip\n",
    "\n",
    "**Purpose**: Validate and normalize an SML clip, reporting errors/warnings.\n",
    "\n",
    "**Wraps**: `sml_ast.clip_from_smil_dict` with error capture\n",
    "\n",
    "**Checks**:\n",
    "- Bar durations fill correctly (no overfull/underfull bars)\n",
    "- Pitches are valid MIDI range (0-127)\n",
    "- Velocities are valid (1-127)\n",
    "- Duration tokens are recognized\n",
    "- CC values in range (0-127)\n",
    "- Pitch bend values in range (0-16383)"
   ],
   "id": "validate-clip-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import List, Literal\n",
    "\n",
    "class ValidationIssue(TypedDict):\n",
    "    level: Literal[\"error\", \"warning\", \"info\"]\n",
    "    bar_index: Optional[int]\n",
    "    item_index: Optional[int]\n",
    "    message: str\n",
    "    auto_fixed: bool\n",
    "\n",
    "\n",
    "class ValidationResult(TypedDict):\n",
    "    valid: bool\n",
    "    issues: List[ValidationIssue]\n",
    "    normalized_clip: Optional[Dict[str, Any]]  # Auto-fixed version if possible\n",
    "\n",
    "\n",
    "class ValidateClipParams(TypedDict, total=False):\n",
    "    auto_fix: bool                   # Attempt to fix simple issues (default: True)\n",
    "    strict: bool                     # Fail on warnings too (default: False)\n",
    "    meter: str                       # Expected meter for bar duration check\n",
    "    clamp_velocities: bool           # Clamp velocities to 1-127 (default: True)\n",
    "    clamp_cc: bool                   # Clamp CC values to 0-127 (default: True)\n",
    "\n",
    "\n",
    "def validate_sml_clip(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: Optional[ValidateClipParams] = None,\n",
    ") -> ValidationResult:\n",
    "    \"\"\"Validate an SML clip and optionally auto-fix issues.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip dict\n",
    "    - Output: ValidationResult with issues list and optionally normalized clip\n",
    "    \n",
    "    Auto-fix behaviors:\n",
    "    - Clamp velocities to [1, 127]\n",
    "    - Clamp CC values to [0, 127]\n",
    "    - Round durations to nearest valid unit\n",
    "    - Add missing bar_index fields\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "validate-clip-signature"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LangGraph Node Wrapper\n",
    "\n",
    "class ValidationState(TypedDict, total=False):\n",
    "    sml_clip: Dict[str, Any]\n",
    "    validation_params: ValidateClipParams\n",
    "    validation_result: ValidationResult\n",
    "    error: str\n",
    "\n",
    "\n",
    "async def validate_clip_node(state: ValidationState) -> ValidationState:\n",
    "    \"\"\"LangGraph node: Validate and normalize SML clip.\"\"\"\n",
    "    if state.get(\"error\"):\n",
    "        return state\n",
    "    \n",
    "    sml_clip = state.get(\"sml_clip\")\n",
    "    if not sml_clip:\n",
    "        return {**state, \"error\": \"No sml_clip to validate\"}\n",
    "    \n",
    "    params = state.get(\"validation_params\", {})\n",
    "    result = validate_sml_clip(sml_clip, params)\n",
    "    \n",
    "    # Replace clip with normalized version if available\n",
    "    if result.get(\"normalized_clip\"):\n",
    "        state = {**state, \"sml_clip\": result[\"normalized_clip\"]}\n",
    "    \n",
    "    if not result[\"valid\"]:\n",
    "        errors = [i for i in result[\"issues\"] if i[\"level\"] == \"error\"]\n",
    "        return {**state, \"validation_result\": result, \"error\": f\"Validation failed: {len(errors)} errors\"}\n",
    "    \n",
    "    return {**state, \"validation_result\": result}"
   ],
   "id": "validate-clip-node"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 3. EXPRESSION TOOLS\n",
    "---"
   ],
   "id": "expression-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.1 humanize_velocities\n",
    "\n",
    "**Purpose**: Apply metrical accents and random jitter to note velocities.\n",
    "\n",
    "**See**: `velocity_humanizer.ipynb` for full implementation details."
   ],
   "id": "humanize-ref"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 apply_cc_template\n",
    "\n",
    "**Purpose**: Apply predefined CC curves (mod wheel, expression, filter) to bars.\n",
    "\n",
    "**Templates**:\n",
    "- `crescendo` - Gradual increase over bar\n",
    "- `diminuendo` - Gradual decrease over bar\n",
    "- `swell` - Rise and fall (pad/strings)\n",
    "- `tremolo` - LFO-style oscillation (CC1)\n",
    "- `filter_sweep` - EDM-style filter cutoff (CC74)\n",
    "- `pedal_sustain` - Piano pedal events (CC64)"
   ],
   "id": "cc-template-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Literal, Union\n",
    "\n",
    "class CCTemplateParams(TypedDict, total=False):\n",
    "    template: Literal[\"crescendo\", \"diminuendo\", \"swell\", \"tremolo\", \"filter_sweep\", \"pedal_sustain\"]\n",
    "    controller: int                  # CC number (default depends on template)\n",
    "    start_value: int                 # Starting CC value (0-127)\n",
    "    end_value: int                   # Ending CC value (0-127)\n",
    "    peak_value: int                  # Peak for swell template\n",
    "    peak_position: float             # 0.0-1.0 position of peak in bar\n",
    "    lfo_rate: float                  # Hz for tremolo\n",
    "    lfo_depth: int                   # Amplitude for tremolo\n",
    "    apply_to_bars: Optional[List[int]]  # 1-based bar indices; None = all\n",
    "    intensity: float                 # 0.0-1.0 master scale\n",
    "\n",
    "\n",
    "def apply_cc_template(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: CCTemplateParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Apply a CC template to an SML clip.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip dict, template parameters\n",
    "    - Output: SML clip with bar-level `expression.cc` curves added/modified\n",
    "    \n",
    "    CC curve format in output:\n",
    "        bar[\"expression\"][\"cc\"] = {\n",
    "            1: [{\"time\": 0.0, \"value\": 20}, {\"time\": 2.0, \"value\": 90}, ...],\n",
    "            74: [...]\n",
    "        }\n",
    "    \n",
    "    Common CC numbers:\n",
    "    - CC1: Mod wheel\n",
    "    - CC7: Volume\n",
    "    - CC11: Expression\n",
    "    - CC64: Sustain pedal\n",
    "    - CC74: Filter cutoff (brightness)\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "cc-template-signature"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# OpenAI Function Schema for Expression Agent\n",
    "\n",
    "APPLY_CC_TEMPLATE_SCHEMA = {\n",
    "    \"name\": \"apply_cc_template\",\n",
    "    \"description\": \"Apply a CC automation template to add expression to a clip.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"template\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"crescendo\", \"diminuendo\", \"swell\", \"tremolo\", \"filter_sweep\", \"pedal_sustain\"],\n",
    "                \"description\": \"The type of CC curve to apply\"\n",
    "            },\n",
    "            \"controller\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"minimum\": 0,\n",
    "                \"maximum\": 127,\n",
    "                \"description\": \"MIDI CC number (1=mod wheel, 11=expression, 64=pedal, 74=filter)\"\n",
    "            },\n",
    "            \"start_value\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 127},\n",
    "            \"end_value\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 127},\n",
    "            \"intensity\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0},\n",
    "            \"apply_to_bars\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"integer\", \"minimum\": 1},\n",
    "                \"description\": \"1-based bar indices to apply to; omit for all bars\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"template\"]\n",
    "    }\n",
    "}"
   ],
   "id": "cc-template-schema"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.3 apply_pitch_bend\n",
    "\n",
    "**Purpose**: Add pitch bend curves for glides, scoops, and falls.\n",
    "\n",
    "**Strategies**:\n",
    "- `glide_into_next` - Bend from current note pitch toward next note\n",
    "- `scoop` - Start below pitch, bend up (blues/jazz)\n",
    "- `fall` - End of note bends down\n",
    "- `vibrato` - Periodic pitch oscillation"
   ],
   "id": "pitch-bend-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class PitchBendParams(TypedDict, total=False):\n",
    "    strategy: Literal[\"glide_into_next\", \"scoop\", \"fall\", \"vibrato\"]\n",
    "    \n",
    "    # For glide_into_next\n",
    "    glide_start: float               # 0.0-1.0 position in note to start bend\n",
    "    glide_curve: Literal[\"linear\", \"exponential\", \"s_curve\"]\n",
    "    \n",
    "    # For scoop\n",
    "    scoop_semitones: float           # How far below to start (e.g., 0.5, 1.0, 2.0)\n",
    "    scoop_duration: float            # 0.0-1.0 portion of note for scoop\n",
    "    \n",
    "    # For fall\n",
    "    fall_semitones: float            # How far to fall\n",
    "    fall_start: float                # 0.0-1.0 position to start falling\n",
    "    \n",
    "    # For vibrato\n",
    "    vibrato_rate: float              # Hz\n",
    "    vibrato_depth: float             # Semitones (e.g., 0.25)\n",
    "    vibrato_delay: float             # 0.0-1.0 delay before vibrato starts\n",
    "    \n",
    "    # Common\n",
    "    pitch_bend_range: int            # Semitones (default: 2, synth-dependent)\n",
    "    apply_to_notes: Optional[List[int]]  # 0-based note indices; None = all\n",
    "    apply_to_bars: Optional[List[int]]   # 1-based bar indices; None = all\n",
    "\n",
    "\n",
    "def apply_pitch_bend(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: PitchBendParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Apply pitch bend curves to an SML clip.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip dict, pitch bend parameters\n",
    "    - Output: SML clip with bar-level `expression.pitch_bend_curve` added\n",
    "    \n",
    "    Pitch bend values are 14-bit (0-16383), center at 8192.\n",
    "    Default pitch bend range is 2 semitones, so:\n",
    "    - 8192 = center (no bend)\n",
    "    - 16383 = +2 semitones\n",
    "    - 0 = -2 semitones\n",
    "    \n",
    "    Example output:\n",
    "        bar[\"expression\"][\"pitch_bend_curve\"] = [\n",
    "            {\"time\": 0.0, \"value\": 8192},\n",
    "            {\"time\": 0.75, \"value\": 11000},\n",
    "            {\"time\": 1.0, \"value\": 8192}\n",
    "        ]\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "pitch-bend-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 4. TRANSFORMATION TOOLS\n",
    "---"
   ],
   "id": "transform-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.1 transpose_clip\n",
    "\n",
    "**Purpose**: Transpose all notes by a given interval."
   ],
   "id": "transpose-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TransposeParams(TypedDict, total=False):\n",
    "    semitones: int                   # Interval to transpose (+/- semitones)\n",
    "    octaves: int                     # Shorthand for semitones (1 octave = 12 semitones)\n",
    "    clamp_to_range: bool             # Clamp to MIDI 0-127 (default: True)\n",
    "    preserve_key: bool               # Transpose within key (diatonic) vs chromatic\n",
    "    target_key: str                  # If preserve_key, transpose to this key\n",
    "\n",
    "\n",
    "def transpose_clip(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: TransposeParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Transpose all notes in an SML clip.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip, transpose parameters\n",
    "    - Output: SML clip with transposed note pitches\n",
    "    - Rests are unchanged\n",
    "    - Notes clamped to MIDI range [0, 127] if clamp_to_range=True\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "transpose-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.2 quantize_clip\n",
    "\n",
    "**Purpose**: Snap note start times and durations to a grid."
   ],
   "id": "quantize-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class QuantizeParams(TypedDict, total=False):\n",
    "    grid: Literal[\"quarter\", \"eighth\", \"sixteenth\", \"triplet_eighth\", \"triplet_sixteenth\"]\n",
    "    strength: float                  # 0.0-1.0; 1.0 = full snap, 0.5 = halfway\n",
    "    quantize_starts: bool            # Quantize note start times (default: True)\n",
    "    quantize_durations: bool         # Quantize note durations (default: True)\n",
    "    humanize_after: bool             # Apply small random offset after quantize\n",
    "\n",
    "\n",
    "def quantize_clip(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: QuantizeParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Quantize note timing to a grid.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip, quantize parameters\n",
    "    - Output: SML clip with quantized timing\n",
    "    - Strength < 1.0 moves notes partially toward grid\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "quantize-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.3 apply_swing\n",
    "\n",
    "**Purpose**: Apply swing feel by delaying off-beat notes."
   ],
   "id": "swing-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SwingParams(TypedDict, total=False):\n",
    "    amount: float                    # 0.0-1.0; 0.5 = straight, 0.67 = triplet swing\n",
    "    grid: Literal[\"eighth\", \"sixteenth\"]  # Which subdivision to swing\n",
    "    velocity_accent: bool            # Also accent downbeats (default: False)\n",
    "\n",
    "\n",
    "def apply_swing(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: SwingParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Apply swing timing to a clip.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip, swing parameters\n",
    "    - Output: SML clip with swung timing\n",
    "    \n",
    "    Swing delays every other subdivision:\n",
    "    - amount=0.5: straight (no swing)\n",
    "    - amount=0.67: triplet feel\n",
    "    - amount=0.75: heavy shuffle\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "swing-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4.4 invert_clip / retrograde_clip\n",
    "\n",
    "**Purpose**: Classic compositional transformations."
   ],
   "id": "invert-retro-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class InvertParams(TypedDict, total=False):\n",
    "    axis_pitch: int                  # MIDI pitch to invert around (default: first note)\n",
    "    preserve_rhythm: bool            # Keep original timing (default: True)\n",
    "\n",
    "\n",
    "def invert_clip(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: Optional[InvertParams] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Invert pitches around an axis.\n",
    "    \n",
    "    For each note: new_pitch = 2 * axis_pitch - old_pitch\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class RetrogradeParams(TypedDict, total=False):\n",
    "    preserve_bar_structure: bool     # Keep bars in order, reverse within (default: True)\n",
    "    reverse_bars_too: bool           # Also reverse bar order (default: False)\n",
    "\n",
    "\n",
    "def retrograde_clip(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: Optional[RetrogradeParams] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Reverse the order of notes (retrograde).\n",
    "    \n",
    "    By default, reverses notes within each bar but keeps bar order.\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "invert-retro-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 5. HARMONY TOOLS\n",
    "---"
   ],
   "id": "harmony-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.1 generate_chord_track\n",
    "\n",
    "**Purpose**: Generate chord accompaniment from a melody or chord symbols."
   ],
   "id": "chord-track-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ChordTrackParams(TypedDict, total=False):\n",
    "    source: Literal[\"from_melody\", \"from_symbols\"]  # How to derive chords\n",
    "    chord_symbols: List[str]         # e.g., [\"Cmaj7\", \"Dm7\", \"G7\", \"Cmaj7\"]\n",
    "    voicing: Literal[\"close\", \"open\", \"drop2\", \"drop3\", \"shell\"]\n",
    "    rhythm: Literal[\"whole\", \"half\", \"quarter\", \"comping\"]  # Chord rhythm pattern\n",
    "    register: Literal[\"low\", \"mid\", \"high\"]  # Octave placement\n",
    "    key: str                         # Key for analysis\n",
    "    mode: str                        # \"major\" or \"minor\"\n",
    "\n",
    "\n",
    "def generate_chord_track(\n",
    "    melody_clip: Optional[Dict[str, Any]],\n",
    "    params: ChordTrackParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generate a chord track.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: Optional melody clip (for from_melody), chord parameters\n",
    "    - Output: New SML clip with chord voicings\n",
    "    \n",
    "    If source=\"from_melody\", analyzes melody to suggest chords.\n",
    "    If source=\"from_symbols\", uses provided chord_symbols list.\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "chord-track-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.2 generate_bassline\n",
    "\n",
    "**Purpose**: Generate bass line from chord progression."
   ],
   "id": "bassline-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BasslineParams(TypedDict, total=False):\n",
    "    style: Literal[\"root_only\", \"root_fifth\", \"walking\", \"arpeggiated\", \"syncopated\"]\n",
    "    chord_symbols: List[str]         # Chord progression\n",
    "    octave: int                      # Base octave (default: 2)\n",
    "    rhythm: Literal[\"whole\", \"half\", \"quarter\", \"eighth\"]\n",
    "    key: str\n",
    "    mode: str\n",
    "\n",
    "\n",
    "def generate_bassline(\n",
    "    chord_clip: Optional[Dict[str, Any]],\n",
    "    params: BasslineParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generate a bass line from chords.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: Optional chord clip, bass parameters\n",
    "    - Output: New SML clip with bass line\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "bassline-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.3 arpeggiate_chords\n",
    "\n",
    "**Purpose**: Convert block chords to arpeggios."
   ],
   "id": "arpeggiate-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ArpeggiateParams(TypedDict, total=False):\n",
    "    pattern: Literal[\"up\", \"down\", \"up_down\", \"down_up\", \"random\", \"as_played\"]\n",
    "    rate: Literal[\"eighth\", \"sixteenth\", \"triplet\"]\n",
    "    octave_range: int                # How many octaves to span (default: 1)\n",
    "    gate: float                      # 0.0-1.0 note length relative to rate\n",
    "\n",
    "\n",
    "def arpeggiate_chords(\n",
    "    chord_clip: Dict[str, Any],\n",
    "    params: ArpeggiateParams,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Convert block chords to arpeggios.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip with chords (multiple simultaneous notes)\n",
    "    - Output: SML clip with arpeggiated notes\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "arpeggiate-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 6. PLAYBACK TOOLS\n",
    "---"
   ],
   "id": "playback-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6.1 preview_clip\n",
    "\n",
    "**Purpose**: Play an SML clip through FluidSynth for immediate preview.\n",
    "\n",
    "**Wraps**: `OSCFacade.play_clip_from_sml`"
   ],
   "id": "preview-clip-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class PreviewParams(TypedDict, total=False):\n",
    "    sf2_path: str                    # Path to SoundFont file\n",
    "    bpm: int                         # Tempo (default: 120)\n",
    "    loop: bool                       # Loop playback (default: False)\n",
    "    program: int                     # MIDI program/patch number (0-127)\n",
    "    channel: int                     # MIDI channel (0-15)\n",
    "\n",
    "\n",
    "async def preview_clip(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: Optional[PreviewParams] = None,\n",
    ") -> bool:\n",
    "    \"\"\"Play an SML clip for preview.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip, playback parameters\n",
    "    - Output: True if playback started successfully\n",
    "    - Side effect: Audio plays through FluidSynth\n",
    "    \n",
    "    This is a thin wrapper around OSCFacade.play_clip_from_sml.\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "preview-clip-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 7. STORAGE TOOLS\n",
    "---"
   ],
   "id": "storage-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7.1 store_clip\n",
    "\n",
    "**Purpose**: Store an SML clip to the database with tags.\n",
    "\n",
    "**Wraps**: `OSCFacade.sml_to_dsl_clip` + `ClipService.create_clip_from_dsl`"
   ],
   "id": "store-clip-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class StoreClipParams(TypedDict, total=False):\n",
    "    tags: List[str]                  # Tags to attach\n",
    "    auto_tag: bool                   # Auto-generate tags from content (default: True)\n",
    "    name_override: str               # Override clip name\n",
    "\n",
    "\n",
    "async def store_clip(\n",
    "    sml_clip: Dict[str, Any],\n",
    "    params: Optional[StoreClipParams] = None,\n",
    ") -> int:\n",
    "    \"\"\"Store an SML clip to the database.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML clip, storage parameters\n",
    "    - Output: clip_id of stored clip\n",
    "    \n",
    "    Auto-tagging derives tags from:\n",
    "    - Key/scale (if detectable)\n",
    "    - Tempo range\n",
    "    - Note density\n",
    "    - Instrument (if specified)\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "store-clip-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7.2 search_clips\n",
    "\n",
    "**Purpose**: Search for clips by tags or name pattern.\n",
    "\n",
    "**Wraps**: `OSCFacade.search_clips`"
   ],
   "id": "search-clips-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SearchClipsParams(TypedDict, total=False):\n",
    "    tags: List[str]                  # Tags to match (OR logic)\n",
    "    name_pattern: str                # SQL LIKE pattern (e.g., \"%bass%\")\n",
    "    limit: int                       # Max results (default: 10)\n",
    "\n",
    "\n",
    "async def search_clips(\n",
    "    params: SearchClipsParams,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Search for clips in the database.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: Search parameters\n",
    "    - Output: List of DSL clip dicts\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "search-clips-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 8. EXPORT TOOLS\n",
    "---"
   ],
   "id": "export-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8.1 export_to_midi\n",
    "\n",
    "**Purpose**: Export clip or composition to MIDI file.\n",
    "\n",
    "**Wraps**: `OSCFacade.dsl_to_midi_file`"
   ],
   "id": "export-midi-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ExportMidiParams(TypedDict, total=False):\n",
    "    output_path: str                 # File path for .mid file\n",
    "    include_all_tracks: bool         # Include all tracks (default: True)\n",
    "    tempo_bpm: int                   # Override tempo\n",
    "    include_cc: bool                 # Include CC automation (default: True)\n",
    "    include_pitch_bend: bool         # Include pitch bend (default: True)\n",
    "\n",
    "\n",
    "async def export_to_midi(\n",
    "    clip_or_composition: Dict[str, Any],\n",
    "    params: ExportMidiParams,\n",
    ") -> str:\n",
    "    \"\"\"Export to MIDI file.\n",
    "    \n",
    "    Contract:\n",
    "    - Input: SML/DSL clip or composition, export parameters\n",
    "    - Output: Path to written MIDI file\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "export-midi-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 9. QA TOOLS\n",
    "---"
   ],
   "id": "qa-header"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9.1 lint_clip\n",
    "\n",
    "**Purpose**: Check clip for common issues and anti-patterns."
   ],
   "id": "lint-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LintResult(TypedDict):\n",
    "    issues: List[str]                # List of issue descriptions\n",
    "    score: float                     # 0.0-1.0 quality score\n",
    "    suggestions: List[str]           # Improvement suggestions\n",
    "\n",
    "\n",
    "def lint_clip(sml_clip: Dict[str, Any]) -> LintResult:\n",
    "    \"\"\"Lint an SML clip for quality issues.\n",
    "    \n",
    "    Checks:\n",
    "    - CC spam (too frequent CC changes)\n",
    "    - Velocity extremes (all max or all min)\n",
    "    - Empty bars\n",
    "    - Pitch range issues (too wide or too narrow)\n",
    "    - Duration consistency\n",
    "    - Pitch bend returning to center\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "lint-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9.2 summarize_clip\n",
    "\n",
    "**Purpose**: Generate a human-readable summary of clip contents."
   ],
   "id": "summarize-intro"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ClipSummary(TypedDict):\n",
    "    name: str\n",
    "    num_bars: int\n",
    "    num_notes: int\n",
    "    pitch_range: str                 # e.g., \"C3-G5\"\n",
    "    detected_key: Optional[str]      # e.g., \"C major\"\n",
    "    velocity_range: str              # e.g., \"60-100\"\n",
    "    has_cc: bool\n",
    "    has_pitch_bend: bool\n",
    "    density: str                     # e.g., \"sparse\", \"moderate\", \"dense\"\n",
    "    description: str                 # Natural language summary\n",
    "\n",
    "\n",
    "def summarize_clip(sml_clip: Dict[str, Any]) -> ClipSummary:\n",
    "    \"\"\"Generate a summary of an SML clip.\n",
    "    \n",
    "    Useful for:\n",
    "    - Displaying clip info in UI\n",
    "    - Auto-generating tags\n",
    "    - Explaining clip to user\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "summarize-signature"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# GRAPH WIRING EXAMPLE\n",
    "---\n",
    "\n",
    "Example of wiring multiple nodes into a complete workflow."
   ],
   "id": "wiring-header"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Complete state for the composition workflow\n",
    "class ComposerState(TypedDict, total=False):\n",
    "    # Input\n",
    "    prompt: str\n",
    "    \n",
    "    # Generation params\n",
    "    generate_params: GenerateClipParams\n",
    "    humanize_params: dict  # HumanizeParams from velocity_humanizer\n",
    "    cc_params: CCTemplateParams\n",
    "    \n",
    "    # Intermediate\n",
    "    sml_clip: Dict[str, Any]\n",
    "    validation_result: ValidationResult\n",
    "    \n",
    "    # Output\n",
    "    clip_id: int\n",
    "    export_path: str\n",
    "    \n",
    "    # Control\n",
    "    error: str\n",
    "    feedback: str\n",
    "\n",
    "\n",
    "# Build the graph\n",
    "def build_composer_graph():\n",
    "    graph = StateGraph(ComposerState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph.add_node(\"generate\", generate_clip_node)\n",
    "    graph.add_node(\"validate\", validate_clip_node)\n",
    "    graph.add_node(\"humanize\", apply_velocity_humanization)  # from velocity_humanizer.ipynb\n",
    "    graph.add_node(\"add_expression\", apply_cc_template_node)\n",
    "    graph.add_node(\"preview\", preview_clip_node)\n",
    "    graph.add_node(\"store\", store_clip_node)\n",
    "    graph.add_node(\"export\", export_midi_node)\n",
    "    \n",
    "    # Wire edges\n",
    "    graph.set_entry_point(\"generate\")\n",
    "    graph.add_edge(\"generate\", \"validate\")\n",
    "    graph.add_edge(\"validate\", \"humanize\")\n",
    "    graph.add_edge(\"humanize\", \"add_expression\")\n",
    "    graph.add_edge(\"add_expression\", \"preview\")\n",
    "    graph.add_edge(\"preview\", \"store\")\n",
    "    graph.add_edge(\"store\", \"export\")\n",
    "    graph.add_edge(\"export\", END)\n",
    "    \n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "# Usage\n",
    "async def main():\n",
    "    graph = build_composer_graph()\n",
    "    \n",
    "    state: ComposerState = {\n",
    "        \"prompt\": \"Create a jazzy piano riff in F major, 4 bars\",\n",
    "        \"humanize_params\": {\n",
    "            \"strategy\": \"meter_accent\",\n",
    "            \"meter\": \"4/4\",\n",
    "            \"intensity\": 0.6,\n",
    "        },\n",
    "        \"cc_params\": {\n",
    "            \"template\": \"swell\",\n",
    "            \"controller\": 1,\n",
    "            \"intensity\": 0.4,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    result = await graph.ainvoke(state)\n",
    "    \n",
    "    if result.get(\"error\"):\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"Stored clip ID: {result['clip_id']}\")\n",
    "        print(f\"Exported to: {result['export_path']}\")"
   ],
   "id": "wiring-example"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# IMPLEMENTATION PRIORITY\n",
    "---\n",
    "\n",
    "Suggested order for implementing these tools:\n",
    "\n",
    "## Phase 1: Core Pipeline (MVP)\n",
    "1. `generate_clip_from_nl` - Already exists in clip_graph.py\n",
    "2. `validate_sml_clip` - Essential for catching errors early\n",
    "3. `humanize_velocities` - Designed in velocity_humanizer.ipynb\n",
    "4. `preview_clip` - Already exists via OSCFacade\n",
    "5. `store_clip` - Already exists via OSCFacade\n",
    "\n",
    "## Phase 2: Expression\n",
    "6. `apply_cc_template` - Add dynamics and expression\n",
    "7. `apply_pitch_bend` - Glides and articulations\n",
    "\n",
    "## Phase 3: Transformation\n",
    "8. `transpose_clip` - Basic pitch manipulation\n",
    "9. `quantize_clip` - Timing cleanup\n",
    "10. `apply_swing` - Feel adjustment\n",
    "\n",
    "## Phase 4: Harmony\n",
    "11. `generate_chord_track` - Accompaniment\n",
    "12. `generate_bassline` - Bass lines\n",
    "13. `arpeggiate_chords` - Texture variation\n",
    "\n",
    "## Phase 5: QA & Polish\n",
    "14. `lint_clip` - Quality checks\n",
    "15. `summarize_clip` - User-facing info\n",
    "16. `invert_clip`, `retrograde_clip` - Advanced transforms"
   ],
   "id": "priority-list"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
